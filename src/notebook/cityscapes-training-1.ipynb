{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2122a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision.io import decode_image\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from clearml import Task\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c6ee0",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca8fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    DATA_PATH: str = \"/home/hxastur/vscode-projects/cityscapes-segmentation/dataset\"\n",
    "    ANNOTATIONS_DATA_PATH: str = os.path.join(DATA_PATH, \"gtFine/gtFine\")\n",
    "    ANNOTATIONS_TRAIN_PATH: str = os.path.join(ANNOTATIONS_DATA_PATH, \"train\")\n",
    "    ANNOTATIONS_TEST_PATH: str = os.path.join(ANNOTATIONS_DATA_PATH, \"test\")\n",
    "    ANNOTATIONS_VAL_PATH: str = os.path.join(ANNOTATIONS_DATA_PATH, \"val\")\n",
    "    LEFT_DATA_PATH: str = os.path.join(DATA_PATH, \"left/leftImg8bit\")\n",
    "    LEFT_TRAIN_PATH: str = os.path.join(LEFT_DATA_PATH, \"train\")\n",
    "    LEFT_TEST_PATH: str = os.path.join(LEFT_DATA_PATH, \"test\")\n",
    "    LEFT_VAL_PATH: str = os.path.join(LEFT_DATA_PATH, \"val\")\n",
    "    LEFT_TYPE: str = \"leftImg8bit\"\n",
    "    ANNOTATIONS_PREFIX: str = \"gtFine\"\n",
    "    batch_size: int = 8\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442eeff",
   "metadata": {},
   "source": [
    "# Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f2cc25",
   "metadata": {},
   "source": [
    "[Github Dataset Link](https://github.com/mcordts/cityscapesScripts)\n",
    "\n",
    "The folder structure of the Cityscapes dataset is as follows:\n",
    "\n",
    "**{root}/{type}{video}/{split}/{city}/{city}_{seq:0>6}_{frame:0>6}_{type}{ext}**\n",
    "\n",
    "The meaning of the individual elements is:\n",
    "\n",
    "**root** the root folder of the Cityscapes dataset. Many of our scripts check if an environment variable CITYSCAPES_DATASET pointing to this folder exists and use this as the default choice.\n",
    "\n",
    "**type** the type/modality of data, e.g. gtFine for fine ground truth, or leftImg8bit for left 8-bit images.\n",
    "\n",
    "**split** the split, i.e. train/val/test/train_extra/demoVideo. Note that not all kinds of data exist for all splits. Thus, do not be surprised to occasionally find empty folders.\n",
    "\n",
    "**city** the city in which this part of the dataset was recorded.\n",
    "\n",
    "**seq** the sequence number using 6 digits.\n",
    "\n",
    "**frame** the frame number using 6 digits. Note that in some cities very few, albeit very long sequences were recorded, while in some cities many short sequences were recorded, of which only the 19th frame is annotated.\n",
    "\n",
    "**ext** the extension of the file and optionally a suffix, e.g. _polygons.json for ground truth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7173ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_TYPES = [\"color.png\", \"instanceIds.png\", \"labelIds.png\", \"polygons.json\"]\n",
    "\n",
    "\n",
    "class Processor:\n",
    "    def __init__(\n",
    "        self, LEFT_DATA_PATH, ANNOTATIONS_DATA_PATH, ANNOTATIONS_PREFIX=\"_gtFine\"\n",
    "    ):\n",
    "        self.LEFT_DATA_PATH = LEFT_DATA_PATH\n",
    "        self.ANNOTATIONS_DATA_PATH = ANNOTATIONS_DATA_PATH\n",
    "        self.ANNOTATIONS_PREFIX = ANNOTATIONS_PREFIX\n",
    "\n",
    "    def get_images(self):\n",
    "        images = {}\n",
    "        cities = os.listdir(self.LEFT_DATA_PATH)\n",
    "        for city in cities:\n",
    "            city_left_path = os.path.join(self.LEFT_DATA_PATH, city)\n",
    "            files_left = os.listdir(city_left_path)\n",
    "            for file in files_left:\n",
    "                full_left_path = os.path.join(city_left_path, file)\n",
    "                splitted = file.split(\"_\")\n",
    "                if len(splitted) != 4:\n",
    "                    raise ValueError(\"Len of splitted != 4\")\n",
    "                image_type = \"left\"\n",
    "                image_city = splitted[0]\n",
    "                sequence_number = splitted[1]\n",
    "                frame_number = splitted[2]\n",
    "                image_name = f\"{image_city}_{sequence_number}_{frame_number}\"\n",
    "\n",
    "                train_paths = [\n",
    "                    f\"{image_name}{self.ANNOTATIONS_PREFIX}_{ANNOTATION_TYPE}\"\n",
    "                    for ANNOTATION_TYPE in ANNOTATION_TYPES\n",
    "                ]\n",
    "                image_arr = images.get(image_name, {})\n",
    "                image_arr.update({\"left\": full_left_path})\n",
    "                for ANNOTATION_TYPE in ANNOTATION_TYPES:\n",
    "                    annot_type = ANNOTATION_TYPE.split(\".\")[0]\n",
    "                    image_arr.update(\n",
    "                        {\n",
    "                            annot_type: f\"{image_name}{self.ANNOTATIONS_PREFIX}_{ANNOTATION_TYPE}\"\n",
    "                        }\n",
    "                    )\n",
    "                images.update({image_name: image_arr})\n",
    "\n",
    "        for imgid in images.keys():\n",
    "            if len(images[imgid]) != 5:\n",
    "                raise ValueError(\"Len of arr %5 != 0\")\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19e5ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Processor(\n",
    "    config.LEFT_TRAIN_PATH,\n",
    "    ANNOTATIONS_DATA_PATH=config.ANNOTATIONS_TRAIN_PATH,\n",
    "    ANNOTATIONS_PREFIX=\"gtFine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152a76b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d328c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityscapesDataset(Dataset):\n",
    "    def __init__(self, processor: Processor):\n",
    "        self.images = processor.get_images()\n",
    "        self.keys = list(self.images.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_index = self.keys[idx]\n",
    "        image = self.images[image_index]\n",
    "\n",
    "        color_path = image[\"color\"]\n",
    "        instanceIds_path = image[\"instanceIds\"]\n",
    "        labelIds_path = image[\"labelIds\"]\n",
    "        polygons_path = image[\"polygons\"]\n",
    "\n",
    "        color = decode_image(color_path)\n",
    "        return color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcaf152",
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ed0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.cnn = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.cnn))\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        num_cnn,\n",
    "        pool=False,\n",
    "        upsample=False,\n",
    "        softmax=False,\n",
    "    ):\n",
    "        super(Block, self).__init__()\n",
    "        self.softmax = softmax\n",
    "        self.pool = pool\n",
    "        self.upsample = upsample\n",
    "        if num_cnn == 2:\n",
    "            self.block = nn.ModuleList(\n",
    "                [\n",
    "                    CNNBlock(in_channels=in_channels, out_channels=out_channels),\n",
    "                    CNNBlock(in_channels=out_channels, out_channels=out_channels),\n",
    "                ]\n",
    "            )\n",
    "        if num_cnn == 3:\n",
    "            self.block = nn.ModuleList(\n",
    "                [\n",
    "                    CNNBlock(in_channels=in_channels, out_channels=out_channels),\n",
    "                    CNNBlock(in_channels=out_channels, out_channels=out_channels),\n",
    "                    CNNBlock(in_channels=out_channels, out_channels=out_channels),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.mp = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        self.mup = nn.MaxUnpool2d(2, stride=2)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, ind=None):\n",
    "        for module in self.block:\n",
    "            x = module(x)\n",
    "\n",
    "        if self.pool:\n",
    "            x, ind = self.mp(x)\n",
    "            return x, ind\n",
    "\n",
    "        if self.upsample:\n",
    "            x = self.mup(x, ind)\n",
    "\n",
    "        if self.softmax:\n",
    "            x = self.sm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels=3, out_channels=32, num_two=2, num_blocks=5, channel_step=64\n",
    "    ):\n",
    "        super(SegNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.poolblock = nn.ModuleList(\n",
    "            [\n",
    "                (\n",
    "                    Block(\n",
    "                        in_channels=(\n",
    "                            channel_step * 2 ** (i - 1) if i != 0 else in_channels\n",
    "                        ),\n",
    "                        out_channels=channel_step * 2**i,\n",
    "                        num_cnn=2 if i < num_two else 3,\n",
    "                        pool=True,\n",
    "                    )\n",
    "                )\n",
    "                for i in range(num_blocks)\n",
    "            ]\n",
    "        )\n",
    "        self.unpoolblock = nn.ModuleList(\n",
    "            [\n",
    "                Block(\n",
    "                    in_channels=(channel_step * 2 ** (4 - i)),\n",
    "                    out_channels=(\n",
    "                        channel_step * 2 ** (3 - i)\n",
    "                        if i != num_blocks - 1\n",
    "                        else out_channels\n",
    "                    ),\n",
    "                    num_cnn=2 if i < num_two else 3,\n",
    "                    upsample=True,\n",
    "                    softmax=True if i == num_blocks - 1 else False,\n",
    "                )\n",
    "                for i in range(num_blocks)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        index_list = []\n",
    "        for module in self.poolblock:\n",
    "            x, ind = module(x)\n",
    "            index_list.append(ind)\n",
    "        for i, module in enumerate(self.unpoolblock):\n",
    "            ind = index_list[4 - i]\n",
    "            x = module(x, ind)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "486abac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Processor(config.TRAIN_PATH)\n",
    "dataset = CityscapesDataset(processor)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=config.batch_size)\n",
    "block = SegNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c881dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cityscapes-segmentation-py3.12 (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
